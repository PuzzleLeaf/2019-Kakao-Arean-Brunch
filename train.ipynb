{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import timedelta, datetime\n",
    "import glob\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawProgressBar(percent, barLen = 20):\n",
    "    # percent float from 0 to 1. \n",
    "    sys.stdout.write(\"\\r\")\n",
    "    sys.stdout.write(\"[{:<{}}] {:.0f}%\".format(\"=\" * int(barLen * percent), barLen, percent * 100))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타 데이터\n",
    "metadata = pd.read_json('metadata.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저 데이터\n",
    "users = pd.read_json('users.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 데이터\n",
    "read_file_lst = glob.glob('res/read/*')\n",
    "exclude_file_lst = ['read.tar']\n",
    "\n",
    "read_df_lst = []\n",
    "for f in read_file_lst:\n",
    "    file_name = os.path.basename(f)\n",
    "    if file_name in exclude_file_lst:\n",
    "        print(file_name)\n",
    "    else:\n",
    "        df_temp = pd.read_csv(f, header=None, names=['raw'])\n",
    "        df_temp['dt'] = file_name[:8]\n",
    "        df_temp['hr'] = file_name[8:10]\n",
    "        df_temp['user_id'] = df_temp['raw'].str.split(' ').str[0]\n",
    "        df_temp['article_id'] = df_temp['raw'].str.split(' ').str[1:].str.join(' ').str.strip()\n",
    "        read_df_lst.append(df_temp)\n",
    "        \n",
    "read = pd.concat(read_df_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 데이터 가공\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(' ')))\n",
    "read_cnt_by_user = read['article_id'].str.split(' ').map(len)\n",
    "read_raw = pd.DataFrame({'dt': np.repeat(read['dt'], read_cnt_by_user),\n",
    "                         'hr': np.repeat(read['hr'], read_cnt_by_user),\n",
    "                         'user_id': np.repeat(read['user_id'], read_cnt_by_user),\n",
    "                         'article_id': chainer(read['article_id'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글별 소비수 통계\n",
    "atc_read_cnt = read_raw[read_raw.article_id != ''].groupby('article_id')['user_id'].count()\n",
    "atc_read_cnt = atc_read_cnt.reset_index()\n",
    "atc_read_cnt.columns = ['article_id', 'read_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc = metadata.copy()\n",
    "atc['reg_datetime'] = atc['reg_ts'].apply(lambda x : datetime.fromtimestamp(x/1000.0))\n",
    "atc.loc[atc['reg_datetime'] == atc['reg_datetime'].min(), 'reg_datetime'] = datetime(2090, 12, 31)\n",
    "atc['reg_dt'] = atc['reg_datetime'].dt.date\n",
    "atc['type'] = atc['magazine_id'].apply(lambda x : '개인' if x == 0.0 else '매거진')\n",
    "# 컬럼명 변경\n",
    "atc.columns = ['id', 'display_url', 'article_id', 'keyword_list', 'magazine_id', 'reg_ts', 'sub_title', 'title', 'author_id', 'reg_datetime', 'reg_dt', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata 결합\n",
    "atc_read_cnt = pd.merge(atc_read_cnt, atc, how='left', left_on='article_id', right_on='article_id')\n",
    "atc_read_cnt_nn = atc_read_cnt[atc_read_cnt['id'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_cnt_frame = atc_read_cnt_nn.sort_values([\"read_cnt\"], ascending=[False])\n",
    "optimize_frame = read_cnt_frame.drop(['id', 'display_url', 'sub_title', 'magazine_id', 'reg_ts', 'title', 'author_id', 'reg_dt', 'type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article 기반 데이터 정제\n",
    "article_detail_dic = {}\n",
    "for row in optimize_frame.values:\n",
    "    article_detail_dic[row[0]] = {'read_cnt': row[1], 'keyword': row[2] ,'datetime': row[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저별 팔로우 목록\n",
    "user_follow_dict = {}\n",
    "for row in users.values:\n",
    "    user_id = row[1]\n",
    "    follow_list = row[0]\n",
    "    user_follow_dict[user_id] = follow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTime (dateTime):\n",
    "    if dateTime == 0:\n",
    "        return 0\n",
    "    t = pd.Timestamp(dateTime)\n",
    "    return time.mktime(t.timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 유저별 읽은 글 목록\n",
    "user_read_dic = {}\n",
    "for row in read_raw.values:\n",
    "    user_id = row[2]\n",
    "    article = row[3]\n",
    "    if user_read_dic.get(user_id, \"empty\") == \"empty\":\n",
    "        user_read_dic[user_id] = [article]\n",
    "    else:\n",
    "        user_read_dic[user_id].append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_cnt_max = max(read_cnt_frame.read_cnt)\n",
    "reg_datetime_max = max(read_cnt_frame[read_cnt_frame.reg_datetime < '2090-12-31'].reg_datetime)\n",
    "reg_datetime_max = convertTime(reg_datetime_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저별 팔로우 목록\n",
    "user_follow_dict = {}\n",
    "for row in users.values:\n",
    "    user_id = row[1]\n",
    "    follow_list = row[0]\n",
    "    user_follow_dict[user_id] = follow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 읽은 글에 대한 팔로우 가중치 계산에 사용\n",
    "def to_timeScore(dt_time):\n",
    "    return time.mktime(datetime.strptime(dt_time[6:8] +\"/\"+dt_time[4:6]+\"/\"+dt_time[:4], \"%d/%m/%Y\").timetuple()) * (0.2 / reg_datetime_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeywordTimeScore(datetime):\n",
    "    return convertTime(data['datetime']) * (0.2 / reg_datetime_max) #최근 글 일수록 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최근 읽은 글일 수록 가중치 추가\n",
    "def getArticleTimeScore(article, userId):\n",
    "    if article_detail_dic.get(article, \"empty\") == \"empty\":\n",
    "        return to_timeScore(user_last_read_dic[userId][article])\n",
    "    \n",
    "    data = article_detail_dic[article]\n",
    "    return convertTime(data['datetime']) * (0.3 / reg_datetime_max) #최근 글 일수록 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticleScore(article):\n",
    "    data = article_detail_dic[article]\n",
    "    cnt_p = data['read_cnt'] * (0.02 / read_cnt_max) # 읽은 사람이 많을 수록 가중치\n",
    "    time_p = convertTime(data['datetime']) * (0.35 / reg_datetime_max) #최근 글 일수록 가중치\n",
    "    time_p = time_p if time_p <= 0.35 else 0\n",
    "    return cnt_p + time_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드에 대한 상관관계 파악\n",
    "user_keyword_article_read_dic = {}\n",
    "for id in user_read_dic:\n",
    "    article_read_dic = {}\n",
    "    read_articles = user_read_dic[id]\n",
    "    for article in read_articles:\n",
    "        if article_detail_dic.get(article, \"empty\") == \"empty\":\n",
    "            continue\n",
    "        data = article_detail_dic[article]\n",
    "        for keyword in data['keyword']:\n",
    "            if (article_read_dic.get(keyword, \"empty\") == \"empty\"):\n",
    "                article_read_dic[keyword] = getKeywordTimeScore(data['datetime'])\n",
    "            else:\n",
    "                article_read_dic[keyword] += getKeywordTimeScore(data['datetime'])\n",
    "           \n",
    "    user_keyword_article_read_dic[id] = article_read_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeywordRanking (id):\n",
    "    if (user_keyword_article_read_dic.get(id, \"empty\") == \"empty\") | (len(user_keyword_article_read_dic[id]) == 0):\n",
    "        return {}\n",
    "    rank_dic = dict(sorted(user_keyword_article_read_dic[id].items(), key=lambda x:x[1], reverse = True))\n",
    "    rank_max = max(rank_dic.values())\n",
    "    p1 = 0.3 / rank_max # 최대 가중치 0.3\n",
    "    \n",
    "    result = {}\n",
    "    for item in rank_dic:\n",
    "        result[item] = rank_dic[item] * p1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeywordAvgScore (keyword_dic, article):\n",
    "    if article_detail_dic.get(article, \"empty\") == \"empty\":\n",
    "        return 0\n",
    "    result = 0\n",
    "    cnt = 0\n",
    "    keyword_list = article_detail_dic[article]['keyword']\n",
    "    for keyword in keyword_list:\n",
    "        if keyword_dic.get(keyword, \"empty\") == \"empty\":\n",
    "            continue\n",
    "        result += keyword_dic[keyword]\n",
    "        cnt += 1\n",
    "    return result if result == 0 else result / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeywordMaxScore (keyword_dic, article):\n",
    "    # 키워드 정보 없음\n",
    "    if article_detail_dic.get(article, \"empty\") == \"empty\":\n",
    "        return 0\n",
    "    result = []\n",
    "    keyword_list = article_detail_dic[article]['keyword']\n",
    "    for keyword in keyword_list:\n",
    "        if keyword_dic.get(keyword, \"empty\") == \"empty\":\n",
    "            continue\n",
    "        result.append(keyword_dic[keyword])\n",
    "    return max(result) if len(result) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_last_read_dic = {}\n",
    "for row in read_raw.values:\n",
    "    if user_last_read_dic.get(row[2], \"empty\") == \"empty\":\n",
    "        user_last_read_dic[row[2]] = {}\n",
    "    user_last_read_dic[row[2]][row[3]] = row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 유저마다 팔로우 하고있는 작가별 읽은 글의 수\n",
    "user_follow_article_read_dic = {}\n",
    "for id in user_read_dic:\n",
    "    article_read_dic = {}\n",
    "    read_articles = user_read_dic[id]\n",
    "    for article in read_articles:\n",
    "        follow_id = article.split('_')[0]\n",
    "        # 팔로우가 없는 경우\n",
    "        if (user_follow_dict.get(id, \"empty\") == \"empty\"):\n",
    "            user_follow_dict[id] = []\n",
    "            continue\n",
    "            \n",
    "        if (follow_id in user_follow_dict[id]):\n",
    "            if (article_read_dic.get(follow_id, \"empty\") == \"empty\"):\n",
    "                article_read_dic[follow_id] = getArticleTimeScore(article, id);\n",
    "            else:\n",
    "                article_read_dic[follow_id] += getArticleTimeScore(article, id)\n",
    "    user_follow_article_read_dic[id] = article_read_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFollowingRanking (id):\n",
    "    if (user_follow_article_read_dic.get(id, \"empty\") == \"empty\") | (len(user_follow_article_read_dic[id]) == 0):\n",
    "        return {}\n",
    "    rank_dic = dict(sorted(user_follow_article_read_dic[id].items(), key=lambda x:x[1], reverse = True))\n",
    "    rank_max = max(rank_dic.values())\n",
    "    p1 = 0.4 / rank_max # 최대 가중치 0.4\n",
    "    \n",
    "    result = {}\n",
    "    for item in rank_dic:\n",
    "        result[item] = rank_dic[item] * p1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 유저 목록\n",
    "predict_users = pd.read_csv('res/predict/dev.users', names=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keyword_ranking_dic = {}\n",
    "for id in predict_users.user_id:\n",
    "    user_keyword_ranking_dic[id] = getKeywordRanking(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cmtyx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 2월 15일 이후 인기글 전체\n",
    "train_data = atc_read_cnt_nn.sort_values([\"read_cnt\"], ascending=[False])[(atc_read_cnt_nn.reg_datetime > \"2019-02-01\") & (atc_read_cnt_nn.reg_datetime < \"2090-12-31\")].article_id\n",
    "train_data = list(train_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19862\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = []\n",
    "users_arr = predict_users.user_id\n",
    "for user in users_arr:\n",
    "    user_read_article = []\n",
    "    user_read_article.append(user)\n",
    "    for ar in train_data:\n",
    "        if ar in user_read_dic[user]:\n",
    "            user_read_article.append(1)\n",
    "        else:\n",
    "            user_read_article.append(0)\n",
    "    my_data.append(user_read_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_column_list = list(train_data)\n",
    "article_column_list.insert(0, 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>@brunch_151</th>\n",
       "      <th>@brunch_152</th>\n",
       "      <th>@hjl0520_26</th>\n",
       "      <th>@seochogirl_28</th>\n",
       "      <th>@mothertive_66</th>\n",
       "      <th>@roysday_314</th>\n",
       "      <th>@ohmygod_42</th>\n",
       "      <th>@boot0715_115</th>\n",
       "      <th>@hjl0520_28</th>\n",
       "      <th>...</th>\n",
       "      <th>@kayyoon_25</th>\n",
       "      <th>@g702_15</th>\n",
       "      <th>@g702_11</th>\n",
       "      <th>@g702_16</th>\n",
       "      <th>@g702_18</th>\n",
       "      <th>@nightoffice_7</th>\n",
       "      <th>@vridge_5</th>\n",
       "      <th>@vroongprime_64</th>\n",
       "      <th>@gaudi817_6</th>\n",
       "      <th>@geniyang_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#d6866a498157771069fdf15361cb012b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#f963fb8c5d9d14d503fc4e80bd8617b4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#87a6479c91e4276374378f1d28eb307c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#677e984e245b344f61dc5d3cc1f352c8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#519f45eb14e4807e8714fb7e835463eb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19863 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id  @brunch_151  @brunch_152  @hjl0520_26  \\\n",
       "0  #d6866a498157771069fdf15361cb012b            0            0            0   \n",
       "1  #f963fb8c5d9d14d503fc4e80bd8617b4            0            0            0   \n",
       "2  #87a6479c91e4276374378f1d28eb307c            1            0            0   \n",
       "3  #677e984e245b344f61dc5d3cc1f352c8            1            0            0   \n",
       "4  #519f45eb14e4807e8714fb7e835463eb            0            0            0   \n",
       "\n",
       "   @seochogirl_28  @mothertive_66  @roysday_314  @ohmygod_42  @boot0715_115  \\\n",
       "0               0               0             0            1              0   \n",
       "1               0               0             0            0              0   \n",
       "2               0               0             0            0              0   \n",
       "3               0               0             0            0              0   \n",
       "4               1               0             0            0              0   \n",
       "\n",
       "   @hjl0520_28  ...  @kayyoon_25  @g702_15  @g702_11  @g702_16  @g702_18  \\\n",
       "0            0  ...            0         0         0         0         0   \n",
       "1            0  ...            0         0         0         0         0   \n",
       "2            0  ...            0         0         0         0         0   \n",
       "3            0  ...            0         0         0         0         0   \n",
       "4            0  ...            0         0         0         0         0   \n",
       "\n",
       "   @nightoffice_7  @vridge_5  @vroongprime_64  @gaudi817_6  @geniyang_18  \n",
       "0               0          0                0            0             0  \n",
       "1               0          0                0            0             0  \n",
       "2               0          0                0            0             0  \n",
       "3               0          0                0            0             0  \n",
       "4               0          0                0            0             0  \n",
       "\n",
       "[5 rows x 19863 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테이블 만들기\n",
    "user_article_table = pd.DataFrame(my_data, columns=article_column_list, index=[idx for idx in range(0, len(my_data))])\n",
    "user_article_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "del my_data\n",
    "del article_column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_preds = collections.defaultdict(list)\n",
    "ids = predict_users.user_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in user_article_table.columns:\n",
    "    if c != 'user_id':\n",
    "        # 3000명 중 아무도 읽은 사람이 없는경우 학습이 되지 않으므로 예외처리\n",
    "        if len(set(user_article_table[c].values)) == 1:\n",
    "            for id, p in zip(ids, [0] * 3000) :\n",
    "                id_preds[id].append(p)\n",
    "            continue;\n",
    "            \n",
    "        y_train = user_article_table[c]\n",
    "        x_train = user_article_table.drop([c, 'user_id'], 1)\n",
    "        \n",
    "        clf = LogisticRegression(solver='liblinear')\n",
    "        clf.fit(x_train, y_train)\n",
    "        p_train = clf.predict_proba(x_train)[:,1]\n",
    "        for id, p in zip(ids, p_train):\n",
    "            id_preds[id].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100%"
     ]
    }
   ],
   "source": [
    "# 1차 학습 이후 가중치 추가\n",
    "step = 0\n",
    "train_preds = {}\n",
    "columns = list(user_article_table.columns[1:])\n",
    "for id in predict_users.user_id:\n",
    "    p = id_preds[id].copy()\n",
    "    \n",
    "    for idx in range(0, len(columns)):\n",
    "        follow = columns[idx].split('_')[0]\n",
    "        article_rank = getFollowingRanking(id)\n",
    "        if follow in user_follow_dict[id]:\n",
    "            if article_rank.get(follow, \"empty\") != \"empty\":\n",
    "                p[idx] += article_rank[follow] + getArticleScore(columns[idx]) + getKeywordAvgScore(user_keyword_ranking_dic[id], columns[idx]) # 팔로우 가중치\n",
    "        #p[idx] += getArticleScore(columns[idx]) + getKeywordMaxScore(user_keyword_ranking_dic[id], columns[idx]) \n",
    "    step += 1\n",
    "    drawProgressBar(step / 3000)\n",
    "    preds = [i[0] for i in sorted([i for i in zip(columns, p) if i[0] not in user_read_dic[id]], key=lambda i:i [1], reverse=True)[:100]]\n",
    "    train_preds[id] = preds # 예측값 저장\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cmtyx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 2차 학습\n",
    "train_data2 = atc_read_cnt_nn.sort_values([\"read_cnt\"], ascending=[False])[(atc_read_cnt_nn.reg_datetime < \"2019-02-01\")].article_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append\n",
    "test_c = list(train_data2)\n",
    "test_p = [0] * len(train_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100%"
     ]
    }
   ],
   "source": [
    "# 2차 가중치 설정\n",
    "step = 0\n",
    "train_preds2 = {}\n",
    "columns = test_c.copy()\n",
    "for id in predict_users.user_id:\n",
    "    p = test_p.copy()\n",
    "\n",
    "    for idx in range(0, len(columns)):\n",
    "        follow = columns[idx].split('_')[0]\n",
    "        article_rank = getFollowingRanking(id)\n",
    "        if follow in user_follow_dict[id]:\n",
    "            if article_rank.get(follow, \"empty\") != \"empty\":\n",
    "                p[idx] += (article_rank[follow]) # 팔로우 가중치\n",
    "        p[idx] += getArticleScore(columns[idx]) + getKeywordAvgScore(user_keyword_ranking_dic[id], columns[idx]) \n",
    "    step += 1\n",
    "    drawProgressBar(step / 3000)\n",
    "    preds = [i[0] for i in sorted([i for i in zip(columns, p) if i[0] not in user_read_dic[id]], key=lambda i:i [1], reverse=True)[:100]]\n",
    "    train_preds2[id] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100개 추출하기\n",
    "result = {}\n",
    "for id in ids:\n",
    "    result[id] = train_preds[id][:30]\n",
    "    result[id].extend(train_preds2[id][:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장하기\n",
    "save_data = []\n",
    "for idx in range(0, len(predict_users.user_id)):\n",
    "    user_id = predict_users.user_id[idx]\n",
    "    temp = [user_id]\n",
    "    temp.extend(result[user_id])\n",
    "    temp = [' '.join(temp)]  \n",
    "    save_data.append(temp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = pd.DataFrame(save_data)\n",
    "save.to_csv(\"recommend.txt\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _entropy_diversity(recs, topn):\n",
    "    sz = float(len(recs)) * topn\n",
    "    freq = {}\n",
    "    for u, rec in six.iteritems(recs):\n",
    "        for r in rec:\n",
    "            freq[r] = freq.get(r, 0) + 1\n",
    "    ent = -sum([v / sz * math.log(v / sz) for v in six.itervalues(freq)])\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(recs_path, topn=100):\n",
    "    recs = {}\n",
    "    target_users = set()\n",
    "    for line in open(recs_path):\n",
    "        tkns = line.split()\n",
    "        userid, rec = tkns[0], tkns[1:]\n",
    "        target_users.add(userid)\n",
    "        recs[userid] = rec\n",
    "    print('EntDiv@%s: %s' % (topn, _entropy_diversity(recs, topn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntDiv@100: 10.281624147630335\n"
     ]
    }
   ],
   "source": [
    "evaluate('recommend.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cmtyx\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 2차 학습\n",
    "train_data3 = atc_read_cnt_nn.sort_values([\"read_cnt\"], ascending=[False])[(atc_read_cnt_nn.reg_datetime < \"2019-02-01\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "withJoy = {}\n",
    "for line in open('joy2.txt'):\n",
    "    tkns = line.split()\n",
    "    userid, rec = tkns[0], tkns[1:]\n",
    "    withJoy[userid] = rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(withJoy['#d6866a498157771069fdf15361cb012b'][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# withJoy 100개 추출하기\n",
    "joy_result = {}\n",
    "for id in ids:\n",
    "    joy_result[id] = withJoy[id][:20]\n",
    "    joy_result[id].extend(train_preds2[id][:80])\n",
    "    #검증\n",
    "    if len(set(joy_result[id])) != 100:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장하기\n",
    "save_data = []\n",
    "for idx in range(0, len(predict_users.user_id)):\n",
    "    user_id = predict_users.user_id[idx]\n",
    "    temp = [user_id]\n",
    "    temp.extend(joy_result[user_id])\n",
    "    temp = [' '.join(temp)]  \n",
    "    save_data.append(temp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = pd.DataFrame(save_data)\n",
    "save.to_csv(\"recommend.txt\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
